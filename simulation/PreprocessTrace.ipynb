{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dd1915e-86ba-4fd7-8f0f-b9e27052116a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5d2c970-8a11-45c4-be0c-1cfdfdb8fa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"pai_all.csv\"\n",
    "data_original = pd.read_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23614298-3d1d-4f27-b943-ed5a0dd5484d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original['status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04b8eebd-c624-4cbb-98ae-e33849a8843a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove failed cases\n",
    "data_original = data_original[data_original.status != 'Failed']\n",
    "# Remove 0 util cases\n",
    "data_original = data_original[data_original.gpu_wrk_util != 0]\n",
    "# Remove 0 mem cases\n",
    "data_original = data_original[data_original.max_gpu_wrk_mem != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c576eda6-2672-4b00-a4fa-565917c41b34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Running', 'Terminated'], dtype=object)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_original['status'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8b8ca56d-c545-4ede-862e-272c402889d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original=data_original.dropna(subset=['runtime', 'start_time_t', 'end_time_t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba880ef0-4ed4-4e6b-ae4c-41b641d80920",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_original=data_original.sort_values(by=['start_time_t'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "adfc9421-6197-4121-afa6-6d37ecc83930",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = 'pai_all_post.csv'\n",
    "data_original.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fcf9a014-88ee-431f-a70b-781444b0944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "file_path = \"pai_all_post.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "util_list=data['gpu_wrk_util'].to_list()\n",
    "start_time_list=data['start_time_t'].to_list()\n",
    "mem_list=data['max_gpu_wrk_mem'].to_list()\n",
    "duration_list=data['runtime'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a9e0ae-5949-496f-9aef-213d8165333d",
   "metadata": {},
   "source": [
    "# Burst days 20-40 to be X:1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "01af2eff-dba3-42e3-898c-8ac8bed17937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num infer 498797, num train 155518, infer:train 3.21\n",
      "1598278\n",
      "1598278\n",
      "Num infer 1555180, num train 155518, infer:train 10.00\n"
     ]
    }
   ],
   "source": [
    "infer_ind = []\n",
    "train_ind = []\n",
    "first_time = start_time_list[0]\n",
    "\n",
    "for i,t in enumerate(start_time_list):\n",
    "    if ((start_time_list[i]-first_time)>=20*24*3600) and ((start_time_list[i]-first_time)<40*24*3600):\n",
    "        if (duration_list[i] <= 50000) and (util_list[i] <= 20): #2:1:14000 #3:1 50,000\n",
    "            infer_ind.append(i)\n",
    "        else:\n",
    "            train_ind.append(i)\n",
    "print(\"Num infer %d, num train %d, infer:train %.2f\"%(len(infer_ind), len(train_ind), len(infer_ind)/len(train_ind)))\n",
    "burst_level = 10\n",
    "inc_samples = burst_level*len(train_ind)-len(infer_ind)\n",
    "sample_ind = np.random.choice(np.array(infer_ind), size=inc_samples, replace=True, p=None)\n",
    "# sample_ind = []\n",
    "data_days = data.copy()\n",
    "post_util_list = data_days['gpu_wrk_util'].to_list()\n",
    "post_start_time_list = data_days['start_time_t'].to_list()\n",
    "post_mem_list = data_days['max_gpu_wrk_mem'].to_list()\n",
    "post_duration_list = data_days['runtime'].to_list()\n",
    "post_job_name_list = data_days['job_name'].to_list()\n",
    "post_num_inst_list = data_days['inst_num'].to_list()\n",
    "print(len(post_start_time_list))\n",
    "print(len(post_util_list))\n",
    "for ind in sample_ind:\n",
    "    post_util_list.append(util_list[ind])\n",
    "    post_start_time_list.append(start_time_list[ind])\n",
    "    post_mem_list.append(mem_list[ind])\n",
    "    post_duration_list.append(duration_list[ind])\n",
    "    post_job_name_list.append(job_name_list[ind])\n",
    "    post_num_inst_list.append(num_inst_list[ind])\n",
    "infer_cnt = 0\n",
    "train_cnt = 0\n",
    "\n",
    "for i in range(len(post_start_time_list)):\n",
    "    if ((post_start_time_list[i]-first_time)>=20*24*3600) and ((post_start_time_list[i]-first_time)<40*24*3600):\n",
    "        if (post_duration_list[i] <= 50000) and (post_util_list[i] <= 20):\n",
    "            infer_cnt = infer_cnt+1\n",
    "        else:\n",
    "            train_cnt = train_cnt+1\n",
    "\n",
    "print(\"Num infer %d, num train %d, infer:train %.2f\"%(infer_cnt, train_cnt, infer_cnt/train_cnt))\n",
    "data_burst = {'gpu_wrk_util': post_util_list, \n",
    "              'start_time_t': post_start_time_list,\n",
    "              'max_gpu_wrk_mem': post_mem_list,\n",
    "              'runtime': post_duration_list,\n",
    "              'job_name': post_job_name_list,\n",
    "              'inst_num': post_num_inst_list} \n",
    "data_burst = pd.DataFrame(data_burst) \n",
    "file_path = 'pai_all_burst_3_%d_3.csv'%(burst_level)\n",
    "data_burst.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c2fe38f-773f-431a-93b1-26ad53b35ee2",
   "metadata": {},
   "source": [
    "## Burst during day 20-40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11cb01d2-7f23-4d5f-8562-622c6a19a911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num infer 498797, num train 155518, infer:train 3.21\n"
     ]
    }
   ],
   "source": [
    "infer_ind = []\n",
    "train_ind = []\n",
    "first_time = start_time_list[0]\n",
    "\n",
    "for i,t in enumerate(start_time_list):\n",
    "    if ((start_time_list[i]-first_time)>=20*24*3600) and ((start_time_list[i]-first_time)<40*24*3600):\n",
    "        if (duration_list[i] <= 50000) and (util_list[i] <= 20): #2:1:14000 #3:1 50,000\n",
    "            infer_ind.append(i)\n",
    "        else:\n",
    "            train_ind.append(i)\n",
    "print(\"Num infer %d, num train %d, infer:train %.2f\"%(len(infer_ind), len(train_ind), len(infer_ind)/len(train_ind)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "045063fd-2e7b-446e-835f-4208d1ad3bbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1598278\n",
      "1598278\n",
      "Num infer 997594, num train 155518, infer:train 6.41\n"
     ]
    }
   ],
   "source": [
    "# inc_samples = len(train_ind)*6-len(infer_ind)\n",
    "# sample_ind = np.random.choice(np.array(infer_ind), size=inc_samples, replace=False, p=None)\n",
    "sample_ind = infer_ind.copy()\n",
    "# sample_ind = []\n",
    "data_days = data.copy()\n",
    "post_util_list = data_days['gpu_wrk_util'].to_list()\n",
    "post_start_time_list = data_days['start_time_t'].to_list()\n",
    "post_mem_list = data_days['max_gpu_wrk_mem'].to_list()\n",
    "post_duration_list = data_days['runtime'].to_list()\n",
    "post_job_name_list = data_days['job_name'].to_list()\n",
    "post_num_inst_list = data_days['inst_num'].to_list()\n",
    "print(len(post_start_time_list))\n",
    "print(len(post_util_list))\n",
    "for ind in sample_ind:\n",
    "    post_util_list.append(util_list[ind])\n",
    "    post_start_time_list.append(start_time_list[ind])\n",
    "    post_mem_list.append(mem_list[ind])\n",
    "    post_duration_list.append(duration_list[ind])\n",
    "    post_job_name_list.append(job_name_list[ind])\n",
    "    post_num_inst_list.append(num_inst_list[ind])\n",
    "infer_cnt = 0\n",
    "train_cnt = 0\n",
    "\n",
    "for i in range(len(post_start_time_list)):\n",
    "    if ((post_start_time_list[i]-first_time)>=20*24*3600) and ((post_start_time_list[i]-first_time)<40*24*3600):\n",
    "        if (post_duration_list[i] <= 50000) and (post_util_list[i] <= 20):\n",
    "            infer_cnt = infer_cnt+1\n",
    "        else:\n",
    "            train_cnt = train_cnt+1\n",
    "\n",
    "print(\"Num infer %d, num train %d, infer:train %.2f\"%(infer_cnt, train_cnt, infer_cnt/train_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a3165c40-1e9c-4b26-af84-a49b909631f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_burst = {'gpu_wrk_util': post_util_list, \n",
    "              'start_time_t': post_start_time_list,\n",
    "              'max_gpu_wrk_mem': post_mem_list,\n",
    "              'runtime': post_duration_list,\n",
    "              'job_name': post_job_name_list,\n",
    "              'inst_num': post_num_inst_list} \n",
    "data_burst = pd.DataFrame(data_burst) \n",
    "file_path = 'pai_all_burst_363.csv'\n",
    "data_burst.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7344534e-2fd0-431f-8220-2e19f36377fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num infer 111965, num train 859, infer:train 130.34\n",
      "112824\n",
      "112824\n",
      "Num infer 223930, num train 859, infer:train 260.69\n"
     ]
    }
   ],
   "source": [
    "infer_ind = []\n",
    "train_ind = []\n",
    "first_time = start_time_list[0]\n",
    "\n",
    "for i,t in enumerate(start_time_list[start_ind:end_ind]):\n",
    "    if ((start_time_list[start_ind+i]-first_time)>=21*24*3600) and ((start_time_list[start_ind+i]-first_time)<24*24*3600):\n",
    "        if (duration_list[start_ind+i] <= 247400) and (util_list[start_ind+i] <= 89):\n",
    "            infer_ind.append(start_ind+i)\n",
    "        else:\n",
    "            train_ind.append(start_ind+i)\n",
    "print(\"Num infer %d, num train %d, infer:train %.2f\"%(len(infer_ind), len(train_ind), len(infer_ind)/len(train_ind)))\n",
    "# print(\"Num infer %d, num train %d\"%(len(infer_ind), len(train_ind)))\n",
    "# inc_samples = len(train_ind)*6-len(infer_ind)\n",
    "# sample_ind = np.random.choice(np.array(infer_ind), size=inc_samples, replace=False, p=None)\n",
    "sample_ind = infer_ind.copy()\n",
    "# sample_ind = []\n",
    "data_days = data[start_ind:end_ind]\n",
    "post_util_list = data_days['gpu_wrk_util'].to_list()\n",
    "post_start_time_list = data_days['start_time_t'].to_list()\n",
    "post_mem_list = data_days['max_gpu_wrk_mem'].to_list()\n",
    "post_duration_list = data_days['runtime'].to_list()\n",
    "post_job_name_list = data_days['job_name'].to_list()\n",
    "post_num_inst_list = data_days['inst_num'].to_list()\n",
    "print(len(post_start_time_list))\n",
    "print(len(post_util_list))\n",
    "for ind in sample_ind:\n",
    "    post_util_list.append(util_list[ind])\n",
    "    post_start_time_list.append(start_time_list[ind])\n",
    "    post_mem_list.append(mem_list[ind])\n",
    "    post_duration_list.append(duration_list[ind])\n",
    "    post_job_name_list.append(job_name_list[ind])\n",
    "    post_num_inst_list.append(num_inst_list[ind])\n",
    "    \n",
    "infer_cnt = 0\n",
    "train_cnt = 0\n",
    "\n",
    "for i in range(len(post_start_time_list)):\n",
    "    if ((post_start_time_list[i]-first_time)>=21*24*3600) and ((post_start_time_list[i]-first_time)<24*24*3600):\n",
    "        if (post_duration_list[i] <= 247400) and (post_util_list[i] <= 89):\n",
    "            infer_cnt = infer_cnt+1\n",
    "        else:\n",
    "            train_cnt = train_cnt+1\n",
    "\n",
    "print(\"Num infer %d, num train %d, infer:train %.2f\"%(infer_cnt, train_cnt, infer_cnt/train_cnt))\n",
    "\n",
    "data_burst = {'gpu_wrk_util': post_util_list, \n",
    "              'start_time_t': post_start_time_list,\n",
    "              'max_gpu_wrk_mem': post_mem_list,\n",
    "              'runtime': post_duration_list,\n",
    "              'job_name': post_job_name_list,\n",
    "              'inst_num': post_num_inst_list} \n",
    "data_burst = pd.DataFrame(data_burst) \n",
    "file_path = 'trace_3_days_burstAll.csv'\n",
    "data_burst.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fb848e2d-fabd-4505-86db-7374f308323d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 0.999954 days\n"
     ]
    }
   ],
   "source": [
    "start_t = 30*24*3600\n",
    "end_t = 31*24*3600\n",
    "th_t = 200000\n",
    "th_u = 20\n",
    "# end_t = start_t+3*3600\n",
    "\n",
    "for i,t in enumerate(start_time_list):\n",
    "    if t-start_time_list[0] >= start_t:\n",
    "        start_ind = i\n",
    "        break\n",
    "for i,t in enumerate(start_time_list):\n",
    "    if t-start_time_list[0] >= end_t:\n",
    "        end_ind = i\n",
    "        break\n",
    "\n",
    "duration = (start_time_list[end_ind]-start_time_list[start_ind])/3600/24\n",
    "print(\"Total %f days\"%(duration))\n",
    "\n",
    "data_day = data[start_ind:end_ind]\n",
    "file_path = 'trace_1_day.csv'\n",
    "data_day.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2aa7ef34-ef47-4959-97e3-8331619b5667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 0.999954 days\n",
      "Num infer 28182, num train 11543, infer:train 2.44\n",
      "39725\n",
      "39725\n",
      "Num infer 84546, num train 11543, infer:train 7.32\n"
     ]
    }
   ],
   "source": [
    "start_t = 21*24*3600\n",
    "end_t = 22*24*3600\n",
    "th_t = 200000\n",
    "th_u = 20\n",
    "# end_t = start_t+3*3600\n",
    "\n",
    "for i,t in enumerate(start_time_list):\n",
    "    if t-start_time_list[0] >= start_t:\n",
    "        start_ind = i\n",
    "        break\n",
    "for i,t in enumerate(start_time_list):\n",
    "    if t-start_time_list[0] >= end_t:\n",
    "        end_ind = i\n",
    "        break\n",
    "\n",
    "duration = (start_time_list[end_ind]-start_time_list[start_ind])/3600/24\n",
    "print(\"Total %f days\"%(duration))\n",
    "\n",
    "infer_ind = []\n",
    "train_ind = []\n",
    "first_time = start_time_list[0]\n",
    "\n",
    "for i,t in enumerate(start_time_list[start_ind:end_ind]):\n",
    "    if ((start_time_list[start_ind+i]-first_time)>=21*24*3600) and ((start_time_list[start_ind+i]-first_time)<22*24*3600):\n",
    "        if (duration_list[start_ind+i] <= th_t) and (util_list[start_ind+i] <= th_u):\n",
    "            infer_ind.append(start_ind+i)\n",
    "        else:\n",
    "            train_ind.append(start_ind+i)\n",
    "print(\"Num infer %d, num train %d, infer:train %.2f\"%(len(infer_ind), len(train_ind), len(infer_ind)/len(train_ind)))\n",
    "# print(\"Num infer %d, num train %d\"%(len(infer_ind), len(train_ind)))\n",
    "# inc_samples = len(train_ind)*6-len(infer_ind)\n",
    "# sample_ind = np.random.choice(np.array(infer_ind), size=inc_samples, replace=False, p=None)\n",
    "sample_ind = infer_ind.copy()\n",
    "# sample_ind = []\n",
    "data_days = data[start_ind:end_ind]\n",
    "post_util_list = data_days['gpu_wrk_util'].to_list()\n",
    "post_start_time_list = data_days['start_time_t'].to_list()\n",
    "post_mem_list = data_days['max_gpu_wrk_mem'].to_list()\n",
    "post_duration_list = data_days['runtime'].to_list()\n",
    "post_job_name_list = data_days['job_name'].to_list()\n",
    "post_num_inst_list = data_days['inst_num'].to_list()\n",
    "print(len(post_start_time_list))\n",
    "print(len(post_util_list))\n",
    "times_to_append = 2\n",
    "for ind in sample_ind:\n",
    "    post_util_list  += [util_list[ind]] * times_to_append\n",
    "    post_start_time_list += [start_time_list[ind]] * times_to_append\n",
    "    post_mem_list += [mem_list[ind]] * times_to_append\n",
    "    post_duration_list += [duration_list[ind]] * times_to_append\n",
    "    post_job_name_list += [job_name_list[ind]] * times_to_append\n",
    "    post_num_inst_list += [num_inst_list[ind]] * times_to_append\n",
    "    \n",
    "infer_cnt = 0\n",
    "train_cnt = 0\n",
    "\n",
    "for i in range(len(post_start_time_list)):\n",
    "    if ((post_start_time_list[i]-first_time)>=21*24*3600) and ((post_start_time_list[i]-first_time)<22*24*3600):\n",
    "        if (post_duration_list[i] <= th_t) and (post_util_list[i] <= th_u):\n",
    "            infer_cnt = infer_cnt+1\n",
    "        else:\n",
    "            train_cnt = train_cnt+1\n",
    "\n",
    "print(\"Num infer %d, num train %d, infer:train %.2f\"%(infer_cnt, train_cnt, infer_cnt/train_cnt))\n",
    "\n",
    "data_burst = {'gpu_wrk_util': post_util_list, \n",
    "              'start_time_t': post_start_time_list,\n",
    "              'max_gpu_wrk_mem': post_mem_list,\n",
    "              'runtime': post_duration_list,\n",
    "              'job_name': post_job_name_list,\n",
    "              'inst_num': post_num_inst_list} \n",
    "data_burst = pd.DataFrame(data_burst) \n",
    "# file_path = 'trace_1_day_burstAll20u.csv'\n",
    "file_path = 'trace_1_day_burst_3_X_3.csv'\n",
    "\n",
    "data_burst.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "22cae957-4007-4d8d-baa8-60cc5382a45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 2.999919 days\n",
      "Num infer 84152, num train 28672, infer:train 2.93\n",
      "112824\n",
      "112824\n",
      "Num infer 589064, num train 28672, infer:train 20.54\n"
     ]
    }
   ],
   "source": [
    "start_t = 21*24*3600\n",
    "end_t = 24*24*3600\n",
    "th_t = 50000\n",
    "th_u = 20\n",
    "# end_t = start_t+3*3600\n",
    "\n",
    "for i,t in enumerate(start_time_list):\n",
    "    if t-start_time_list[0] >= start_t:\n",
    "        start_ind = i\n",
    "        break\n",
    "for i,t in enumerate(start_time_list):\n",
    "    if t-start_time_list[0] >= end_t:\n",
    "        end_ind = i\n",
    "        break\n",
    "\n",
    "duration = (start_time_list[end_ind]-start_time_list[start_ind])/3600/24\n",
    "print(\"Total %f days\"%(duration))\n",
    "\n",
    "infer_ind = []\n",
    "train_ind = []\n",
    "first_time = start_time_list[0]\n",
    "\n",
    "for i,t in enumerate(start_time_list[start_ind:end_ind]):\n",
    "    if ((start_time_list[start_ind+i]-first_time)>=start_t) and ((start_time_list[start_ind+i]-first_time)<end_t):\n",
    "        if (duration_list[start_ind+i] <= th_t) and (util_list[start_ind+i] <= th_u):\n",
    "            infer_ind.append(start_ind+i)\n",
    "        else:\n",
    "            train_ind.append(start_ind+i)\n",
    "print(\"Num infer %d, num train %d, infer:train %.2f\"%(len(infer_ind), len(train_ind), len(infer_ind)/len(train_ind)))\n",
    "# print(\"Num infer %d, num train %d\"%(len(infer_ind), len(train_ind)))\n",
    "# inc_samples = len(train_ind)*6-len(infer_ind)\n",
    "# sample_ind = np.random.choice(np.array(infer_ind), size=inc_samples, replace=False, p=None)\n",
    "sample_ind = infer_ind.copy()\n",
    "# sample_ind = []\n",
    "data_days = data[start_ind:end_ind]\n",
    "post_util_list = data_days['gpu_wrk_util'].to_list()\n",
    "post_start_time_list = data_days['start_time_t'].to_list()\n",
    "post_mem_list = data_days['max_gpu_wrk_mem'].to_list()\n",
    "post_duration_list = data_days['runtime'].to_list()\n",
    "post_job_name_list = data_days['job_name'].to_list()\n",
    "post_num_inst_list = data_days['inst_num'].to_list()\n",
    "print(len(post_start_time_list))\n",
    "print(len(post_util_list))\n",
    "times_to_append = 6\n",
    "for ind in sample_ind:\n",
    "    post_util_list  += [util_list[ind]] * times_to_append\n",
    "    post_start_time_list += [start_time_list[ind]] * times_to_append\n",
    "    post_mem_list += [mem_list[ind]] * times_to_append\n",
    "    post_duration_list += [duration_list[ind]] * times_to_append\n",
    "    post_job_name_list += [job_name_list[ind]] * times_to_append\n",
    "    post_num_inst_list += [num_inst_list[ind]] * times_to_append\n",
    "    \n",
    "infer_cnt = 0\n",
    "train_cnt = 0\n",
    "\n",
    "for i in range(len(post_start_time_list)):\n",
    "    if ((post_start_time_list[i]-first_time)>=start_t) and ((post_start_time_list[i]-first_time)<end_t):\n",
    "        if (post_duration_list[i] <= th_t) and (post_util_list[i] <= th_u):\n",
    "            infer_cnt = infer_cnt+1\n",
    "        else:\n",
    "            train_cnt = train_cnt+1\n",
    "\n",
    "print(\"Num infer %d, num train %d, infer:train %.2f\"%(infer_cnt, train_cnt, infer_cnt/train_cnt))\n",
    "\n",
    "data_burst = {'gpu_wrk_util': post_util_list, \n",
    "              'start_time_t': post_start_time_list,\n",
    "              'max_gpu_wrk_mem': post_mem_list,\n",
    "              'runtime': post_duration_list,\n",
    "              'job_name': post_job_name_list,\n",
    "              'inst_num': post_num_inst_list} \n",
    "data_burst = pd.DataFrame(data_burst) \n",
    "file_path = 'trace_3_days_%d_1.csv'%(3*(times_to_append+1))\n",
    "\n",
    "data_burst.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "c65aac49-b633-4d5f-a5e8-5454ee4a0a19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 20.000069 days\n",
      "Num infer 21107, num train 7838, infer:train 2.69\n",
      "379119\n",
      "379119\n",
      "Num infer 84428, num train 7838, infer:train 10.77\n"
     ]
    }
   ],
   "source": [
    "start_t = 0*24*3600\n",
    "end_t = 20*24*3600\n",
    "start_t2 = 10*24*3600\n",
    "end_t2 = 11*24*3600\n",
    "th_t = 50000\n",
    "th_u = 20\n",
    "# end_t = start_t+3*3600\n",
    "\n",
    "for i,t in enumerate(start_time_list):\n",
    "    if t-start_time_list[0] >= start_t:\n",
    "        start_ind = i\n",
    "        break\n",
    "for i,t in enumerate(start_time_list):\n",
    "    if t-start_time_list[0] >= end_t:\n",
    "        end_ind = i\n",
    "        break\n",
    "\n",
    "duration = (start_time_list[end_ind]-start_time_list[start_ind])/3600/24\n",
    "print(\"Total %f days\"%(duration))\n",
    "\n",
    "infer_ind = []\n",
    "train_ind = []\n",
    "first_time = start_time_list[0]\n",
    "\n",
    "for i,t in enumerate(start_time_list[start_ind:end_ind]):\n",
    "    if ((start_time_list[start_ind+i]-first_time)>=start_t2) and ((start_time_list[start_ind+i]-first_time)<end_t2):\n",
    "        if (duration_list[start_ind+i] <= th_t) and (util_list[start_ind+i] <= th_u):\n",
    "            infer_ind.append(start_ind+i)\n",
    "        else:\n",
    "            train_ind.append(start_ind+i)\n",
    "print(\"Num infer %d, num train %d, infer:train %.2f\"%(len(infer_ind), len(train_ind), len(infer_ind)/len(train_ind)))\n",
    "# print(\"Num infer %d, num train %d\"%(len(infer_ind), len(train_ind)))\n",
    "# burst_level = 12\n",
    "# inc_samples = burst_level*len(train_ind)-len(infer_ind)\n",
    "# sample_ind = np.random.choice(np.array(infer_ind), size=inc_samples, replace=True, p=None)\n",
    "# sample_ind = np.concatenate((infer_ind, sample_ind), axis = 0) \n",
    "sample_ind = infer_ind.copy()\n",
    "# sample_ind = []\n",
    "data_days = data[start_ind:end_ind]\n",
    "post_util_list = data_days['gpu_wrk_util'].to_list()\n",
    "post_start_time_list = data_days['start_time_t'].to_list()\n",
    "post_mem_list = data_days['max_gpu_wrk_mem'].to_list()\n",
    "post_duration_list = data_days['runtime'].to_list()\n",
    "post_job_name_list = data_days['job_name'].to_list()\n",
    "post_num_inst_list = data_days['inst_num'].to_list()\n",
    "print(len(post_start_time_list))\n",
    "print(len(post_util_list))\n",
    "times_to_append = 3\n",
    "for ind in sample_ind:\n",
    "    post_util_list  += [util_list[ind]]*times_to_append\n",
    "    post_start_time_list += [start_time_list[ind]]*times_to_append\n",
    "    post_mem_list += [mem_list[ind]]*times_to_append\n",
    "    post_duration_list += [duration_list[ind]]*times_to_append\n",
    "    post_job_name_list += [job_name_list[ind]]*times_to_append\n",
    "    post_num_inst_list += [num_inst_list[ind]]*times_to_append\n",
    "    \n",
    "infer_cnt = 0\n",
    "train_cnt = 0\n",
    "\n",
    "for i in range(len(post_start_time_list)):\n",
    "    if ((post_start_time_list[i]-first_time)>=start_t2) and ((post_start_time_list[i]-first_time)<end_t2):\n",
    "        if (post_duration_list[i] <= th_t) and (post_util_list[i] <= th_u):\n",
    "            infer_cnt = infer_cnt+1\n",
    "        else:\n",
    "            train_cnt = train_cnt+1\n",
    "\n",
    "print(\"Num infer %d, num train %d, infer:train %.2f\"%(infer_cnt, train_cnt, infer_cnt/train_cnt))\n",
    "\n",
    "data_burst = {'gpu_wrk_util': post_util_list, \n",
    "              'start_time_t': post_start_time_list,\n",
    "              'max_gpu_wrk_mem': post_mem_list,\n",
    "              'runtime': post_duration_list,\n",
    "              'job_name': post_job_name_list,\n",
    "              'inst_num': post_num_inst_list} \n",
    "data_burst = pd.DataFrame(data_burst) \n",
    "# file_path = 'trace_3_days_3_%d_3_u%d_t%d.csv'%(burst_level, th_u, th_t)\n",
    "file_path = 'trace_3_days_3_%d_3_v4.csv'%(times_to_append*3+3)\n",
    "\n",
    "data_burst.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "86da8d20-c228-4ed4-bf47-c994ad898434",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 2.999919 days\n",
      "Num infer 27265, num train 9781, infer:train 2.79\n",
      "112824\n",
      "112824\n",
      "Num infer 117372, num train 9781, infer:train 12.00\n"
     ]
    }
   ],
   "source": [
    "start_t = 21*24*3600\n",
    "end_t = 24*24*3600\n",
    "start_t2 = 22*24*3600\n",
    "end_t2 = 23*24*3600\n",
    "th_t = 50000\n",
    "th_u = 20\n",
    "# end_t = start_t+3*3600\n",
    "\n",
    "for i,t in enumerate(start_time_list):\n",
    "    if t-start_time_list[0] >= start_t:\n",
    "        start_ind = i\n",
    "        break\n",
    "for i,t in enumerate(start_time_list):\n",
    "    if t-start_time_list[0] >= end_t:\n",
    "        end_ind = i\n",
    "        break\n",
    "\n",
    "duration = (start_time_list[end_ind]-start_time_list[start_ind])/3600/24\n",
    "print(\"Total %f days\"%(duration))\n",
    "\n",
    "infer_ind = []\n",
    "train_ind = []\n",
    "first_time = start_time_list[0]\n",
    "\n",
    "for i,t in enumerate(start_time_list[start_ind:end_ind]):\n",
    "    if ((start_time_list[start_ind+i]-first_time)>=start_t2) and ((start_time_list[start_ind+i]-first_time)<end_t2):\n",
    "        if (duration_list[start_ind+i] <= th_t) and (util_list[start_ind+i] <= th_u):\n",
    "            infer_ind.append(start_ind+i)\n",
    "        else:\n",
    "            train_ind.append(start_ind+i)\n",
    "print(\"Num infer %d, num train %d, infer:train %.2f\"%(len(infer_ind), len(train_ind), len(infer_ind)/len(train_ind)))\n",
    "# print(\"Num infer %d, num train %d\"%(len(infer_ind), len(train_ind)))\n",
    "burst_level = 12\n",
    "inc_samples = burst_level*len(train_ind)-len(infer_ind)\n",
    "sample_ind = np.random.choice(np.array(infer_ind), size=inc_samples, replace=True, p=None)\n",
    "# sample_ind = np.concatenate((infer_ind, sample_ind), axis = 0) \n",
    "# sample_ind = infer_ind.copy()\n",
    "# sample_ind = []\n",
    "data_days = data[start_ind:end_ind]\n",
    "post_util_list = data_days['gpu_wrk_util'].to_list()\n",
    "post_start_time_list = data_days['start_time_t'].to_list()\n",
    "post_mem_list = data_days['max_gpu_wrk_mem'].to_list()\n",
    "post_duration_list = data_days['runtime'].to_list()\n",
    "post_job_name_list = data_days['job_name'].to_list()\n",
    "post_num_inst_list = data_days['inst_num'].to_list()\n",
    "print(len(post_start_time_list))\n",
    "print(len(post_util_list))\n",
    "# times_to_append = 1\n",
    "for ind in sample_ind:\n",
    "    post_util_list  += [util_list[ind]]\n",
    "    post_start_time_list += [start_time_list[ind]]\n",
    "    post_mem_list += [mem_list[ind]]\n",
    "    post_duration_list += [duration_list[ind]]\n",
    "    post_job_name_list += [job_name_list[ind]]\n",
    "    post_num_inst_list += [num_inst_list[ind]]\n",
    "    \n",
    "infer_cnt = 0\n",
    "train_cnt = 0\n",
    "\n",
    "for i in range(len(post_start_time_list)):\n",
    "    if ((post_start_time_list[i]-first_time)>=start_t2) and ((post_start_time_list[i]-first_time)<end_t2):\n",
    "        if (post_duration_list[i] <= th_t) and (post_util_list[i] <= th_u):\n",
    "            infer_cnt = infer_cnt+1\n",
    "        else:\n",
    "            train_cnt = train_cnt+1\n",
    "\n",
    "print(\"Num infer %d, num train %d, infer:train %.2f\"%(infer_cnt, train_cnt, infer_cnt/train_cnt))\n",
    "\n",
    "data_burst = {'gpu_wrk_util': post_util_list, \n",
    "              'start_time_t': post_start_time_list,\n",
    "              'max_gpu_wrk_mem': post_mem_list,\n",
    "              'runtime': post_duration_list,\n",
    "              'job_name': post_job_name_list,\n",
    "              'inst_num': post_num_inst_list} \n",
    "data_burst = pd.DataFrame(data_burst) \n",
    "# file_path = 'trace_3_days_3_%d_3_u%d_t%d.csv'%(burst_level, th_u, th_t)\n",
    "file_path = 'trace_3_days_3_%d_3.csv'%(burst_level)\n",
    "\n",
    "data_burst.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ac903d6-0189-4075-9f75-414c9ceadeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27265\n",
      "9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([443475, 443477, 443478, ..., 452338, 469731, 464484])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(infer_ind))\n",
    "print(len(train_ind))\n",
    "sample_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "45e20b97-ba76-4db4-af6a-2fede0f79ca0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total 10.000058 days\n"
     ]
    }
   ],
   "source": [
    "start_t = 10*24*3600\n",
    "end_t = 20*24*3600\n",
    "# end_t = start_t+3*3600\n",
    "\n",
    "for i,t in enumerate(start_time_list):\n",
    "    if t-start_time_list[0] >= start_t:\n",
    "        start_ind = i\n",
    "        break\n",
    "for i,t in enumerate(start_time_list):\n",
    "    if t-start_time_list[0] >= end_t:\n",
    "        end_ind = i\n",
    "        break\n",
    "\n",
    "duration = (start_time_list[end_ind]-start_time_list[start_ind])/3600/24\n",
    "print(\"Total %f days\"%(duration))\n",
    "\n",
    "data_day = data[start_ind:end_ind]\n",
    "file_path = 'trace_10_days.csv'\n",
    "data_day.to_csv(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe7f00-aca1-4d7f-96f9-a4542a0a64b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
